{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9f7cf20e-1c27-4539-be62-c3a8e31e07f4",
   "metadata": {},
   "source": [
    "# Data loading and cleaning\n",
    "### In this process new datasets were loaded into the notebook and stored in the the raw data folder. \n",
    "#### raw data files are then cleaned and saved into the processed data files. The orginal datasets will stay intact in the raw data folder and will not be changed. \n",
    "\n",
    "## Load mosquito data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49430c6f-a9aa-4306-8f32-31ccab22a1cc",
   "metadata": {},
   "source": [
    "## mosquito data was obtained from the City of Chicago Data Portal\n",
    "### unfortunately, the data shows the date of test and not the date of collection. However, most testing will be done in the same week as collection.\n",
    "### the dataset include partial addresses and the lat/long in decimal degrees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "b135c8fe-f2ab-4447-a8c1-97a4f479bd86",
   "metadata": {
    "is_executing": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SEASON YEAR</th>\n",
       "      <th>WEEK</th>\n",
       "      <th>TEST ID</th>\n",
       "      <th>BLOCK</th>\n",
       "      <th>TRAP</th>\n",
       "      <th>TRAP_TYPE</th>\n",
       "      <th>TEST DATE</th>\n",
       "      <th>NUMBER OF MOSQUITOES</th>\n",
       "      <th>RESULT</th>\n",
       "      <th>SPECIES</th>\n",
       "      <th>LATITUDE</th>\n",
       "      <th>LONGITUDE</th>\n",
       "      <th>LOCATION</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021</td>\n",
       "      <td>22</td>\n",
       "      <td>51815</td>\n",
       "      <td>100XX W OHARE</td>\n",
       "      <td>T909</td>\n",
       "      <td>GRAVID</td>\n",
       "      <td>6/3/21 00:06</td>\n",
       "      <td>19</td>\n",
       "      <td>negative</td>\n",
       "      <td>CULEX PIPIENS/RESTUANS</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021</td>\n",
       "      <td>22</td>\n",
       "      <td>51816</td>\n",
       "      <td>100XX W OHARE</td>\n",
       "      <td>T909</td>\n",
       "      <td>GRAVID</td>\n",
       "      <td>6/3/21 00:06</td>\n",
       "      <td>5</td>\n",
       "      <td>negative</td>\n",
       "      <td>CULEX RESTUANS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021</td>\n",
       "      <td>23</td>\n",
       "      <td>51918</td>\n",
       "      <td>100XX W OHARE</td>\n",
       "      <td>T909</td>\n",
       "      <td>GRAVID</td>\n",
       "      <td>6/10/21 00:06</td>\n",
       "      <td>50</td>\n",
       "      <td>negative</td>\n",
       "      <td>CULEX PIPIENS/RESTUANS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021</td>\n",
       "      <td>33</td>\n",
       "      <td>52988</td>\n",
       "      <td>100XX W OHARE</td>\n",
       "      <td>T909</td>\n",
       "      <td>GRAVID</td>\n",
       "      <td>8/19/21 00:08</td>\n",
       "      <td>50</td>\n",
       "      <td>negative</td>\n",
       "      <td>CULEX PIPIENS/RESTUANS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022</td>\n",
       "      <td>23</td>\n",
       "      <td>53486</td>\n",
       "      <td>100XX W OHARE</td>\n",
       "      <td>T904</td>\n",
       "      <td>GRAVID</td>\n",
       "      <td>6/10/22 00:06</td>\n",
       "      <td>23</td>\n",
       "      <td>negative</td>\n",
       "      <td>CULEX PIPIENS/RESTUANS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SEASON YEAR  WEEK  TEST ID          BLOCK  TRAP TRAP_TYPE      TEST DATE  \\\n",
       "0         2021    22    51815  100XX W OHARE  T909    GRAVID   6/3/21 00:06   \n",
       "1         2021    22    51816  100XX W OHARE  T909    GRAVID   6/3/21 00:06   \n",
       "2         2021    23    51918  100XX W OHARE  T909    GRAVID  6/10/21 00:06   \n",
       "3         2021    33    52988  100XX W OHARE  T909    GRAVID  8/19/21 00:08   \n",
       "4         2022    23    53486  100XX W OHARE  T904    GRAVID  6/10/22 00:06   \n",
       "\n",
       "   NUMBER OF MOSQUITOES    RESULT                 SPECIES  LATITUDE  \\\n",
       "0                    19  negative  CULEX PIPIENS/RESTUANS       3.0   \n",
       "1                     5  negative          CULEX RESTUANS       NaN   \n",
       "2                    50  negative  CULEX PIPIENS/RESTUANS       NaN   \n",
       "3                    50  negative  CULEX PIPIENS/RESTUANS       NaN   \n",
       "4                    23  negative  CULEX PIPIENS/RESTUANS       NaN   \n",
       "\n",
       "   LONGITUDE LOCATION  \n",
       "0        4.0      NaN  \n",
       "1        NaN      NaN  \n",
       "2        NaN      NaN  \n",
       "3        NaN      NaN  \n",
       "4        NaN      NaN  "
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Set the display option to show all columns\n",
    "# pd.set_option('display.max_columns', None)\n",
    "\n",
    "# Read the txt file into a pandas DataFrame\n",
    "data = pd.read_csv('../data/raw_data/West_Nile_Virus__WNV__Mosquito_Test_Results.csv')\n",
    "\n",
    "# Display the first few rows of the DataFrame\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e779f0de-e9fb-4b7f-a9b3-2285cbbf5c4e",
   "metadata": {},
   "source": [
    "## identify missing data\n",
    "### an important step in any analysis is identifying missing data and deciding how to handle it. \n",
    "#### in the mosquito testing dataset, there are missing values for lat/long. These are important values if one is performing spatial analysis. \n",
    "#### depending on the sites, we will try to get the lat/long manually based on the partial addresses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "4595e29c-fd6f-4416-b69d-ea8306e52adf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SEASON YEAR                0\n",
       "WEEK                       0\n",
       "TEST ID                    0\n",
       "BLOCK                      0\n",
       "TRAP                       0\n",
       "TRAP_TYPE                  0\n",
       "TEST DATE                  0\n",
       "NUMBER OF MOSQUITOES       0\n",
       "RESULT                     0\n",
       "SPECIES                    0\n",
       "LATITUDE                5318\n",
       "LONGITUDE               5318\n",
       "LOCATION                5319\n",
       "dtype: int64"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_values_count = data.isnull().sum()\n",
    "missing_values_count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d47f3df2-7bb8-422a-b1cf-b1bccf07f0fd",
   "metadata": {},
   "source": [
    "## find the missing lat/long and group them by block \n",
    "#### the majority of the missing values are in the OHARE airport location. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "f68d6eed-0a84-4b14-9eee-084aca12481d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BLOCK</th>\n",
       "      <th>Missing_Count</th>\n",
       "      <th>Test_Dates</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100XX W OHARE</td>\n",
       "      <td>500</td>\n",
       "      <td>[6/3/21 00:06, 6/10/21 00:06, 8/19/21 00:08, 6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100XX W OHARE AIRPORT</td>\n",
       "      <td>3426</td>\n",
       "      <td>[6/16/17 00:06, 6/3/21 00:06, 6/8/18 00:06, 6/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>115XX S AVENUE L</td>\n",
       "      <td>80</td>\n",
       "      <td>[8/28/07 00:08, 8/1/07 02:08, 10/4/07 00:10, 8...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20XX N DOMINICK ST</td>\n",
       "      <td>142</td>\n",
       "      <td>[7/19/18 00:07, 7/3/19 00:07, 6/12/20 00:06, 8...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30XX S HOYNE</td>\n",
       "      <td>24</td>\n",
       "      <td>[9/18/07 00:09, 7/27/07 11:07, 8/21/07 00:08, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>43XX N ASHLAND</td>\n",
       "      <td>15</td>\n",
       "      <td>[8/21/07 00:08, 9/18/07 00:09, 6/26/07 04:06, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4XX W 127TH</td>\n",
       "      <td>512</td>\n",
       "      <td>[6/16/17 00:06, 8/3/17 00:08, 6/12/20 00:06, 6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>65XX N OAK PARK AVE</td>\n",
       "      <td>31</td>\n",
       "      <td>[8/15/07 00:08, 10/4/07 00:10, 6/5/07 00:06, 6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>79XX S CHICAGO</td>\n",
       "      <td>298</td>\n",
       "      <td>[8/3/17 00:08, 6/10/22 00:06, 6/13/19 00:06, 6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>81XX S ASHLAND</td>\n",
       "      <td>269</td>\n",
       "      <td>[8/3/17 00:08, 6/19/17 00:06, 6/8/18 00:06, 7/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>98XX S AVENUE G</td>\n",
       "      <td>21</td>\n",
       "      <td>[8/2/07 00:08, 8/22/07 00:08, 8/1/07 02:08, 9/...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    BLOCK  Missing_Count  \\\n",
       "0           100XX W OHARE            500   \n",
       "1   100XX W OHARE AIRPORT           3426   \n",
       "2        115XX S AVENUE L             80   \n",
       "3      20XX N DOMINICK ST            142   \n",
       "4            30XX S HOYNE             24   \n",
       "5          43XX N ASHLAND             15   \n",
       "6             4XX W 127TH            512   \n",
       "7     65XX N OAK PARK AVE             31   \n",
       "8          79XX S CHICAGO            298   \n",
       "9          81XX S ASHLAND            269   \n",
       "10        98XX S AVENUE G             21   \n",
       "\n",
       "                                           Test_Dates  \n",
       "0   [6/3/21 00:06, 6/10/21 00:06, 8/19/21 00:08, 6...  \n",
       "1   [6/16/17 00:06, 6/3/21 00:06, 6/8/18 00:06, 6/...  \n",
       "2   [8/28/07 00:08, 8/1/07 02:08, 10/4/07 00:10, 8...  \n",
       "3   [7/19/18 00:07, 7/3/19 00:07, 6/12/20 00:06, 8...  \n",
       "4   [9/18/07 00:09, 7/27/07 11:07, 8/21/07 00:08, ...  \n",
       "5   [8/21/07 00:08, 9/18/07 00:09, 6/26/07 04:06, ...  \n",
       "6   [6/16/17 00:06, 8/3/17 00:08, 6/12/20 00:06, 6...  \n",
       "7   [8/15/07 00:08, 10/4/07 00:10, 6/5/07 00:06, 6...  \n",
       "8   [8/3/17 00:08, 6/10/22 00:06, 6/13/19 00:06, 6...  \n",
       "9   [8/3/17 00:08, 6/19/17 00:06, 6/8/18 00:06, 7/...  \n",
       "10  [8/2/07 00:08, 8/22/07 00:08, 8/1/07 02:08, 9/...  "
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_lat_long_data = data[data['LATITUDE'].isnull() | data['LONGITUDE'].isnull()]\n",
    "\n",
    "# Group by 'BLOCK', count the missing values and list the 'TEST DATE' for each\n",
    "block_missing_summary = missing_lat_long_data.groupby('BLOCK').agg(\n",
    "    Missing_Count=pd.NamedAgg(column='LATITUDE', aggfunc='size'), # Count of missing values\n",
    "    Test_Dates=pd.NamedAgg(column='TEST DATE', aggfunc=lambda x: x.unique().tolist()) # Unique test dates\n",
    ").reset_index()\n",
    "\n",
    "# Display the summary\n",
    "block_missing_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db5a0cf8-24f8-49b4-adb9-b94c7512de11",
   "metadata": {},
   "source": [
    "### This code was used to check to see if there were any lat/long listed for at least one of the block records. To check if this code works, I added fake data in two fields. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "3a2d408c-70c7-4c25-b7ba-4ab0e147768e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BLOCK</th>\n",
       "      <th>LATITUDE</th>\n",
       "      <th>LONGITUDE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100XX W OHARE</td>\n",
       "      <td>[3.0]</td>\n",
       "      <td>[4.0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           BLOCK LATITUDE LONGITUDE\n",
       "0  100XX W OHARE    [3.0]     [4.0]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract the list of blocks with missing lat/long data\n",
    "blocks_with_missing_values = block_missing_summary['BLOCK'].unique()\n",
    "\n",
    "# Filter the original dataset for entries that are in the list of blocks with missing values\n",
    "# but have valid latitude and longitude data\n",
    "blocks_with_valid_lat_long = data[\n",
    "    data['BLOCK'].isin(blocks_with_missing_values) &\n",
    "    data['LATITUDE'].notnull() &\n",
    "    data['LONGITUDE'].notnull()\n",
    "]\n",
    "\n",
    "# Group by 'BLOCK' and list the unique latitude and longitude values for these entries\n",
    "block_valid_lat_long_summary = blocks_with_valid_lat_long.groupby('BLOCK').agg({\n",
    "    'LATITUDE': lambda x: x.unique().tolist(),\n",
    "    'LONGITUDE': lambda x: x.unique().tolist()\n",
    "}).reset_index()\n",
    "\n",
    "# The resulting DataFrame 'block_valid_lat_long_summary' will contain each block along with\n",
    "# the associated valid latitude and longitude values that exist in the dataset.\n",
    "block_valid_lat_long_summary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6866791-93aa-4974-a735-b37db3ef4ac7",
   "metadata": {},
   "source": [
    "### Because I am able to get the lat and long for '100XX W OHARE', '100XX W OHARE AIRPORT', '4XX W 127TH', I will keep them and drop all the others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "289675d5-2bc5-418d-b1b4-cde072815e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the blocks to keep even if they have missing lat/long\n",
    "blocks_to_keep = ['100XX W OHARE', '100XX W OHARE AIRPORT', '4XX W 127TH']\n",
    "\n",
    "# Filter the data to exclude rows with missing lat/long unless the block contains one of the specified blocks to keep\n",
    "data_filtered = data[\n",
    "    (~data['LATITUDE'].isnull() & ~data['LONGITUDE'].isnull()) |  # Keep rows with valid lat/long\n",
    "    (data['BLOCK'].str.contains('|'.join(blocks_to_keep)))  # Or rows that contain the specified blocks\n",
    "]\n",
    "\n",
    "# The resulting DataFrame 'data_filtered' will have the rows with missing values dropped,\n",
    "# except for the specified blocks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5911071e-5cc1-4b2a-bed0-4bfeea60b211",
   "metadata": {},
   "source": [
    "Adding Lat and long for the 3 blocks and saving new dataset to the processed data folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "e5bb10df-f423-4bc1-9de1-c2364150fafe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming your dataframe is named data_filtered\n",
    "# Update the lat/long values for the specified locations\n",
    "data_filtered.loc[data_filtered['BLOCK'] == '100XX W OHARE', ['LATITUDE', 'LONGITUDE']] = 41.978611, -87.904724\n",
    "data_filtered.loc[data_filtered['BLOCK'] == '100XX W OHARE AIRPORT', ['LATITUDE', 'LONGITUDE']] = 41.978611, -87.904724\n",
    "data_filtered.loc[data_filtered['BLOCK'] == '4XX W 127TH', ['LATITUDE', 'LONGITUDE']] = 41.66318849, -87.63267836\n",
    "\n",
    "# Save the updated dataframe to a new CSV file in the same directory\n",
    "data_filtered.to_csv('../data/processed_data/wnv_cleaned.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c998a38f-5245-4596-8e9c-170393d8e865",
   "metadata": {},
   "source": [
    "## The OHARE Airport site has two names. we will simplify this and create one name for the site. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "5e064a90-74f2-4de3-9309-6748d7212d6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['100XX W OHARE AIRPORT' '101XX S STONY ISLAND AVE' '104XX S OGLESBY AVE'\n",
      " '104XX S VINCENNES AVE' '104XX S WALLACE ST' '105XX S CALIFORNIA AVE'\n",
      " '109XX S COTTAGE GROVE AVE' '10XX E 67TH ST' '10XX W 95TH ST'\n",
      " '111XX S ARTESIAN AVE' '112XX S WALLACE ST' '115XX S LOOMIS ST'\n",
      " '119XX S ASHLAND AVE' '119XX S PEORIA ST' '119XX S STATE ST'\n",
      " '11XX S CALIFORNIA AVE' '11XX W CHICAGO AVE' '11XX W ROOSEVELT RD'\n",
      " '122XX S STONY ISLAND AVE' '127XX S DOTY AVE' '129XX S BALTIMORE AVE'\n",
      " '12XX W 120TH ST' '12XX W GREENLEAF AVE' '131XX S BRANDON AVE'\n",
      " '131XX S TORRENCE AVE' '132XX S MACKINAW AVE' '13XX N LARAMIE AVE'\n",
      " '14XX N HUMBOLDT DR' '14XX W 112TH ST' '15XX N LONG AVE'\n",
      " '15XX W GRANVILLE AVE' '15XX W WEBSTER AVE' '17XX N ASHLAND AVE'\n",
      " '17XX N PULASKI RD' '17XX W 95TH ST' '17XX W ADDISON ST'\n",
      " '18XX S INDIANA AVE' '18XX W FARWELL AVE' '18XX W LELAND AVE'\n",
      " '1XX N CENTRAL PARK DR' '21XX N CANNON DR' '21XX N LAWLER AVE'\n",
      " '21XX N STAVE ST' '21XX S HAMLIN AVE' '22XX N CANNON DR'\n",
      " '22XX W 113TH ST' '22XX W 51ST ST' '22XX W 69TH ST' '22XX W PERSHING RD'\n",
      " '24XX E 105TH ST' '25XX S MILLARD AVE' '25XX S THROOP ST'\n",
      " '25XX W GRAND AVE' '26XX E 136TH ST' '27XX S WESTERN AVE'\n",
      " '28XX N FRANCISCO AVE' '29XX N KENNETH AVE' '29XX W 85TH ST'\n",
      " '2XX E 111TH ST' '2XX W 89TH ST' '33XX N RUTHERFORD AVE'\n",
      " '34XX N LONG AVE' '34XX W 77TH ST' '35XX W 116TH ST' '35XX W 51ST ST'\n",
      " '36XX N PITTSBURGH AVE' '37XX E 118TH ST' '37XX N KEDVALE AVE'\n",
      " '37XX N KILBOURN AVE' '37XX S PULASKI RD' '38XX E 115TH ST'\n",
      " '38XX N CALIFORNIA AVE' '39XX N SPRINGFIELD AVE' '39XX S ASHLAND AVE'\n",
      " '3XX E RANDOLPH ST' '3XX W 104TH ST' '3XX W 18TH ST' '40XX N AUSTIN AVE'\n",
      " '40XX N KEDVALE AVE' '40XX N TRIPP AVE' '40XX S DEARBORN ST'\n",
      " '41XX N OAK PARK AVE' '42XX N RICHMOND ST' '42XX W 31ST ST'\n",
      " '42XX W 65TH ST' '45XX N CAMPBELL AVE' '46XX N MELVINA AVE'\n",
      " '46XX N MILWAUKEE AVE' '47XX S CORNELL AVE' '48XX W MONTANA ST'\n",
      " '49XX W BALMORAL AVE' '49XX W SUNNYSIDE AVE' '4XX E 130TH ST'\n",
      " '4XX W 127TH' '4XX W 127TH ST' '50XX S UNION AVE' '51XX N MONT CLARE AVE'\n",
      " '51XX W 63RD PL' '52XX S KOLMAR AVE' '52XX S NORDICA AVE'\n",
      " '52XX W 63RD ST' '53XX W AGATITE AVE' '54XX W PARKER AVE'\n",
      " '55XX S DR MARTIN LUTHER KING JR DR' '55XX S NARRAGANSETT AVE'\n",
      " '58XX N PULASKI RD' '58XX N RIDGE AVE' '58XX N WESTERN AVE'\n",
      " '5XX N STREETER DR' '5XX S CENTRAL AVE' '5XX W 72ND ST'\n",
      " '60XX N AVONDALE AVE' '60XX W ROSCOE ST' '61XX N LEMONT AVE'\n",
      " '61XX S MELVINA AVE' '61XX W FULLERTON AVE' '62XX N MANDELL AVE'\n",
      " '62XX N MCCLELLAN AVE' '63XX W 64TH ST' '64XX S STONY ISLAND AVE'\n",
      " '64XX W STRONG ST' '65XX S RACINE AVE' '65XX W DAKIN ST'\n",
      " '66XX S KILPATRICK AVE' '67XX S KEDZIE AVE' '68XX W BELDEN AVE'\n",
      " '6XX E 91ST PL' '6XX W MONTROSE DR' '70XX N MOSELLE AVE'\n",
      " '70XX W ARMITAGE AVE' '71XX N HARLEM AVE' '71XX S SOUTH SHORE DR'\n",
      " '72XX N OKETO AVE' '73XX S CICERO AVE' '75XX N OAKLEY AVE'\n",
      " '77XX S EBERHART AVE' '79XX W FOSTER AVE' '80XX S KEDZIE AVE'\n",
      " '82XX S KOSTNER AVE' '88XX W HIGGINS RD' '89XX S CARPENTER ST'\n",
      " '89XX S MUSKEGON AVE' '8XX E 138TH ST' '8XX E 91ST ST' '8XX W 37TH PL'\n",
      " '91XX W HIGGINS RD' '93XX S DR MARTIN LUTHER KING JR DR'\n",
      " '96XX S HOYNE AVE' '96XX S LONGWOOD DR' '9XX W GARFIELD BLVD']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "df_ORD = pd.read_csv('../data/processed_data/wnv_cleaned.csv')\n",
    "\n",
    "# Standardize 'BLOCK' values\n",
    "df_ORD['BLOCK'] = df_ORD['BLOCK'].replace(['100XX W OHARE'], '100XX W OHARE AIRPORT')\n",
    "\n",
    "# Verify the change\n",
    "print(df_ORD['BLOCK'].unique())\n",
    "\n",
    "# Save the updated DataFrame back to CSV\n",
    "df_ORD.to_csv('../data/processed_data/wnv_cleaned.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1ff0477-e8a2-4025-9763-af4b300bf8b8",
   "metadata": {},
   "source": [
    "# Synthetic data\n",
    "### in the next block, I have created synthetic data to simulate the number of mosquitoes collected based on the number that were sumbitted for testing. \n",
    "#### While, in this case, the synthetic data is not very useful, it is a good skill to learn. Especially when privacy concerns prevent the sharing of actual data. \n",
    "#### you can simulate data to match the characteristics of the actual data or other parameters. \n",
    "##### in this case, I set a limit of 3,000 for all generated cells except for those in row where total_mosquitoes exceeded that. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "0890230c-19f0-46c6-ae33-48588c486c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Define the function to simulate mos_collect\n",
    "def simulate_mos_collect(row):\n",
    "    max_value = 3000\n",
    "    # Generate a value that is higher than Total_Mosquitoes but doesn't exceed 3000\n",
    "    low = 1\n",
    "    high = max_value - row['Total_Mosquitoes']\n",
    "    if high > low:\n",
    "        return min(max_value, row['Total_Mosquitoes'] + np.random.randint(low, high))\n",
    "    else:\n",
    "        return row['Total_Mosquitoes']\n",
    "\n",
    "# Apply the function to create the new mos_collect column\n",
    "df_mir['mos_collect'] = df_mir.apply(simulate_mos_collect, axis=1)\n",
    "\n",
    "# Save the DataFrame with the new synthetic data\n",
    "df_mir.to_csv('../data/processed_data/wnv_mir.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a9ab58a-85b8-4ac0-b783-e07918a92f34",
   "metadata": {},
   "source": [
    "## Load weather data\n",
    "### the weather data was obtained from NOAA National Centers for Environmental Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "025fd827-b701-46e0-8dac-217f90c17011",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STATION</th>\n",
       "      <th>NAME</th>\n",
       "      <th>DATE</th>\n",
       "      <th>PRCP</th>\n",
       "      <th>TMAX</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>USW00094846</td>\n",
       "      <td>CHICAGO OHARE INTERNATIONAL AIRPORT, IL US</td>\n",
       "      <td>2011-01-30</td>\n",
       "      <td>0.00</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>USW00094846</td>\n",
       "      <td>CHICAGO OHARE INTERNATIONAL AIRPORT, IL US</td>\n",
       "      <td>2011-01-31</td>\n",
       "      <td>0.09</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>USW00094846</td>\n",
       "      <td>CHICAGO OHARE INTERNATIONAL AIRPORT, IL US</td>\n",
       "      <td>2011-02-01</td>\n",
       "      <td>0.74</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>USW00094846</td>\n",
       "      <td>CHICAGO OHARE INTERNATIONAL AIRPORT, IL US</td>\n",
       "      <td>2011-02-02</td>\n",
       "      <td>0.74</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>USW00094846</td>\n",
       "      <td>CHICAGO OHARE INTERNATIONAL AIRPORT, IL US</td>\n",
       "      <td>2011-02-03</td>\n",
       "      <td>0.00</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       STATION                                        NAME        DATE  PRCP  \\\n",
       "0  USW00094846  CHICAGO OHARE INTERNATIONAL AIRPORT, IL US  2011-01-30  0.00   \n",
       "1  USW00094846  CHICAGO OHARE INTERNATIONAL AIRPORT, IL US  2011-01-31  0.09   \n",
       "2  USW00094846  CHICAGO OHARE INTERNATIONAL AIRPORT, IL US  2011-02-01  0.74   \n",
       "3  USW00094846  CHICAGO OHARE INTERNATIONAL AIRPORT, IL US  2011-02-02  0.74   \n",
       "4  USW00094846  CHICAGO OHARE INTERNATIONAL AIRPORT, IL US  2011-02-03  0.00   \n",
       "\n",
       "   TMAX  \n",
       "0    30  \n",
       "1    26  \n",
       "2    23  \n",
       "3    23  \n",
       "4    16  "
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Set the display option to show all columns\n",
    "#pd.set_option('display.max_columns', None)\n",
    "# Read the txt file into a pandas DataFrame\n",
    "wx = pd.read_csv('../data/raw_data/ORD_weather.csv')\n",
    "\n",
    "# Display the first few rows of the DataFrame\n",
    "wx.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60b4a180-1123-4d6d-90cc-230c9c04b63d",
   "metadata": {},
   "source": [
    "### identify missing data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71903747-cb05-42ee-88be-81bc8e016704",
   "metadata": {},
   "source": [
    "There are no missing values so we can proceed with the next step. date ranges\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "5c8a48dc-59ab-4b29-aba7-13c4085f48f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The range of the mosquito dataset is 2007 to 2023\n",
      "The range of the weather dataset is 2011-01-30 to 2023-12-22\n"
     ]
    }
   ],
   "source": [
    "#date range for the mosquito dataset\n",
    "year_min_mos = data['SEASON YEAR'].min()\n",
    "year_max_mos = data['SEASON YEAR'].max()\n",
    "\n",
    "#date range for the weather datasetab\n",
    "year_min_wx = wx['DATE'].min()\n",
    "year_max_wx = wx['DATE'].max()\n",
    "\n",
    "print(f\"The range of the mosquito dataset is {year_min_mos} to {year_max_mos}\")\n",
    "print(f\"The range of the weather dataset is {year_min_wx} to {year_max_wx}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "840cb8ae-ebe1-4b20-baea-34d9c1a067ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SEASON YEAR</th>\n",
       "      <th>WEEK</th>\n",
       "      <th>TEST ID</th>\n",
       "      <th>BLOCK</th>\n",
       "      <th>TRAP</th>\n",
       "      <th>TRAP_TYPE</th>\n",
       "      <th>TEST DATE</th>\n",
       "      <th>NUMBER OF MOSQUITOES</th>\n",
       "      <th>RESULT</th>\n",
       "      <th>SPECIES</th>\n",
       "      <th>LATITUDE</th>\n",
       "      <th>LONGITUDE</th>\n",
       "      <th>LOCATION</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021</td>\n",
       "      <td>22</td>\n",
       "      <td>51815</td>\n",
       "      <td>100XX W OHARE AIRPORT</td>\n",
       "      <td>T909</td>\n",
       "      <td>GRAVID</td>\n",
       "      <td>6/3/21 00:06</td>\n",
       "      <td>19</td>\n",
       "      <td>negative</td>\n",
       "      <td>CULEX PIPIENS/RESTUANS</td>\n",
       "      <td>41.978611</td>\n",
       "      <td>-87.904724</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021</td>\n",
       "      <td>22</td>\n",
       "      <td>51816</td>\n",
       "      <td>100XX W OHARE AIRPORT</td>\n",
       "      <td>T909</td>\n",
       "      <td>GRAVID</td>\n",
       "      <td>6/3/21 00:06</td>\n",
       "      <td>5</td>\n",
       "      <td>negative</td>\n",
       "      <td>CULEX RESTUANS</td>\n",
       "      <td>41.978611</td>\n",
       "      <td>-87.904724</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021</td>\n",
       "      <td>23</td>\n",
       "      <td>51918</td>\n",
       "      <td>100XX W OHARE AIRPORT</td>\n",
       "      <td>T909</td>\n",
       "      <td>GRAVID</td>\n",
       "      <td>6/10/21 00:06</td>\n",
       "      <td>50</td>\n",
       "      <td>negative</td>\n",
       "      <td>CULEX PIPIENS/RESTUANS</td>\n",
       "      <td>41.978611</td>\n",
       "      <td>-87.904724</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021</td>\n",
       "      <td>33</td>\n",
       "      <td>52988</td>\n",
       "      <td>100XX W OHARE AIRPORT</td>\n",
       "      <td>T909</td>\n",
       "      <td>GRAVID</td>\n",
       "      <td>8/19/21 00:08</td>\n",
       "      <td>50</td>\n",
       "      <td>negative</td>\n",
       "      <td>CULEX PIPIENS/RESTUANS</td>\n",
       "      <td>41.978611</td>\n",
       "      <td>-87.904724</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022</td>\n",
       "      <td>23</td>\n",
       "      <td>53486</td>\n",
       "      <td>100XX W OHARE AIRPORT</td>\n",
       "      <td>T904</td>\n",
       "      <td>GRAVID</td>\n",
       "      <td>6/10/22 00:06</td>\n",
       "      <td>23</td>\n",
       "      <td>negative</td>\n",
       "      <td>CULEX PIPIENS/RESTUANS</td>\n",
       "      <td>41.978611</td>\n",
       "      <td>-87.904724</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SEASON YEAR  WEEK  TEST ID                  BLOCK  TRAP TRAP_TYPE  \\\n",
       "0         2021    22    51815  100XX W OHARE AIRPORT  T909    GRAVID   \n",
       "1         2021    22    51816  100XX W OHARE AIRPORT  T909    GRAVID   \n",
       "2         2021    23    51918  100XX W OHARE AIRPORT  T909    GRAVID   \n",
       "3         2021    33    52988  100XX W OHARE AIRPORT  T909    GRAVID   \n",
       "4         2022    23    53486  100XX W OHARE AIRPORT  T904    GRAVID   \n",
       "\n",
       "       TEST DATE  NUMBER OF MOSQUITOES    RESULT                 SPECIES  \\\n",
       "0   6/3/21 00:06                    19  negative  CULEX PIPIENS/RESTUANS   \n",
       "1   6/3/21 00:06                     5  negative          CULEX RESTUANS   \n",
       "2  6/10/21 00:06                    50  negative  CULEX PIPIENS/RESTUANS   \n",
       "3  8/19/21 00:08                    50  negative  CULEX PIPIENS/RESTUANS   \n",
       "4  6/10/22 00:06                    23  negative  CULEX PIPIENS/RESTUANS   \n",
       "\n",
       "    LATITUDE  LONGITUDE LOCATION  \n",
       "0  41.978611 -87.904724      NaN  \n",
       "1  41.978611 -87.904724      NaN  \n",
       "2  41.978611 -87.904724      NaN  \n",
       "3  41.978611 -87.904724      NaN  \n",
       "4  41.978611 -87.904724      NaN  "
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Corrected file path\n",
    "file_path = '../data/processed_data/wnv_cleaned.csv'\n",
    "\n",
    "# Read the CSV file\n",
    "mos_clean = pd.read_csv(file_path)\n",
    "\n",
    "# Display the first few rows of the DataFrame\n",
    "mos_clean.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0c1014e-c9cf-42a0-bf85-78a1aa3efe5b",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### we will trim the mosquito dataset so that it contains only the records from 2011-2023. this will match the weather timeframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "07ba50e9-655b-4f54-89a6-0faf7bc748be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the DataFrame to keep only the records where 'SEASON YEAR' is >= 2011\n",
    "mos_trim = mos_clean[mos_clean['SEASON YEAR'] >= 2011]\n",
    "\n",
    "# Find the minimum value of 'SEASON YEAR' in the filtered DataFrame\n",
    "min_season_year = mos_trim['SEASON YEAR'].min()\n",
    "\n",
    "min_season_year\n",
    "\n",
    "mos_trim.to_csv('../data/processed_data/wnv_11_23.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "3e74cd1f-f7b4-42b5-a387-259fd851313e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   SEASON YEAR          BLOCK  WEEK  Number of Negative Pools  \\\n",
      "0         2018  100XX W OHARE    23                         1   \n",
      "1         2018  100XX W OHARE    24                         2   \n",
      "2         2018  100XX W OHARE    25                         2   \n",
      "3         2018  100XX W OHARE    26                         5   \n",
      "4         2018  100XX W OHARE    27                         1   \n",
      "\n",
      "   Number of Positive Pools  \n",
      "0                         0  \n",
      "1                         0  \n",
      "2                         0  \n",
      "3                         1  \n",
      "4                         0  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'../data/processed_data/wnv_result_summary.csv'"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming df is your DataFrame after reading the CSV\n",
    "df = pd.read_csv('../data/processed_data/wnv_trim.csv')\n",
    "\n",
    "# Group the data by 'season year', 'block', 'week', and 'result' to count occurrences\n",
    "grouped = df.groupby(['SEASON YEAR', 'BLOCK', 'WEEK', 'RESULT']).size().reset_index(name='count')\n",
    "\n",
    "# Pivot the table to have 'result' as columns ('positive', 'negative') and counts as values\n",
    "pivot_table = grouped.pivot_table(index=['SEASON YEAR', 'BLOCK', 'WEEK'], columns='RESULT', values='count', fill_value=0).reset_index()\n",
    "\n",
    "# Rename columns if necessary (e.g., to 'Number of Negative Pools', 'Number of Positive Pools')\n",
    "pivot_table.columns = ['SEASON YEAR', 'BLOCK', 'WEEK', 'Number of Negative Pools', 'Number of Positive Pools']\n",
    "\n",
    "# Display the new table\n",
    "print(pivot_table.head())\n",
    "\n",
    "# Let's save this DataFrame to a new CSV file\n",
    "\n",
    "pivot_table.to_csv('../data/processed_data/wnv_result_summary.csv', index=False)\n",
    "\n",
    "# Providing the path to the newly saved CSV file\n",
    "'../data/processed_data/wnv_result_summary.csv'\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "787bdd05-d82f-422d-9f63-c43bc3e49bba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Year-Week   Avg_TMAX  Total_PRCP\n",
      "0     2011-04  30.000000        0.00\n",
      "1     2011-05  24.714286        1.77\n",
      "2     2011-06  27.428571        0.13\n",
      "3     2011-07  43.714286        0.95\n",
      "4     2011-08  33.428571        0.62\n",
      "..        ...        ...         ...\n",
      "621   2023-48  38.714286        0.94\n",
      "622   2023-49  45.285714        0.36\n",
      "623   2023-50  44.142857        0.41\n",
      "624   2023-51  41.400000        0.51\n",
      "625   2023-52  45.000000        0.16\n",
      "\n",
      "[626 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Step 1: Load the dataset\n",
    "df_wx = pd.read_csv('../data/raw_data/ORD_weather.csv')\n",
    "\n",
    "# Ensure the DATE column is in datetime format\n",
    "df_wx['DATE'] = pd.to_datetime(df_wx['DATE'])\n",
    "\n",
    "# Step 2: Create a 'Year-Week' column in 'YYYY-WW' format\n",
    "df_wx['Year'] = df_wx['DATE'].dt.year\n",
    "df_wx['Week'] = df_wx['DATE'].dt.isocalendar().week\n",
    "df_wx['Year-Week'] = df_wx['Year'].astype(str) + '-' + df_wx['Week'].apply(lambda x: f'{x:02d}')\n",
    "\n",
    "# Step 3: Group by the new 'Year-Week' column and calculate the desired metrics\n",
    "weekly_data = df_wx.groupby('Year-Week').agg(\n",
    "    Avg_TMAX=('TMAX', 'mean'),  # Calculate average of TMAX\n",
    "    Total_PRCP=('PRCP', 'sum')  # Calculate total of PRCP\n",
    ").reset_index()\n",
    "\n",
    "# Display the resulting DataFrame\n",
    "print(weekly_data)\n",
    "\n",
    "# Save the DataFrame to the specified location\n",
    "weekly_data.to_csv('../data/processed_data/wx_weeknum.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "57cd2a88-fb34-460b-907f-597e948bd1b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Working Directory: /Users/andrewruiz/HPAM9000_ruiz/Python\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Check the current working directory\n",
    "print(\"Current Working Directory:\", os.getcwd())\n",
    "\n",
    "# If needed, change to the directory where your notebook should be running from\n",
    "# os.chdir('your/base/directory')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cab8d802-9b75-4d7b-b9fa-b5cee9506f59",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
